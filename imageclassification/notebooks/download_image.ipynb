{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download image from web\n",
    "\n",
    "> #### DON'T use, use chrome extension instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def download_image(url, type):\n",
    "    # Check if directory exists, if not, create it\n",
    "    if not os.path.exists(os.path.join('data', type)):\n",
    "        os.makedirs(os.path.join('data', type))\n",
    "\n",
    "    # Make a request to the website\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Select the div with id 'mw-content-text' and get all 'img' tags within it\n",
    "    content_div = soup.find(id='mw-content-text')\n",
    "    image_tags = content_div.find_all('img')\n",
    "\n",
    "    # Get the 'src' attribute of each 'img' tag and convert relative URLs to absolute URLs\n",
    "    image_urls = [urljoin(url, img['src']) for img in image_tags]\n",
    "\n",
    "    # Get the highest numbered image file in the directory\n",
    "    files = os.listdir(os.path.join('data', type))\n",
    "    if files:\n",
    "        last_file = max(files, key=lambda x: int(x.split('image')[1].split('.jpg')[0]))\n",
    "        start_index = int(last_file.split('image')[1].split('.jpg')[0]) + 1\n",
    "    else:\n",
    "        start_index = 0\n",
    "\n",
    "    # Download each image\n",
    "    for i, url in enumerate(image_urls, start=start_index):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            # Check if the response content type is an image\n",
    "            if 'image' in response.headers['Content-Type']:\n",
    "                with open(os.path.join('data', type, f'image{i}.jpg'), 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print(f'Skipped URL {url} as it is not an image')\n",
    "        except Exception as e:\n",
    "            print(f'Error downloading image from URL {url}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdownload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.google.com/search?sca_esv=022465d531b21f4c&rlz=1C1ONGR_enVN1095VN1095&sxsrf=ACQVn09xjnmZhAgsURHtSjC57FYSDGId_g:1709626979051&q=cat&tbm=isch&source=lnms&sa=X&ved=2ahUKEwiD-KLm2NyEAxVEqVYBHVxUBh0Q0pQJegQIDRAB&biw=1707&bih=898&dpr=1.5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mdownload_image\u001b[1;34m(url, type)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Select the div with id 'mw-content-text' and get all 'img' tags within it\u001b[39;00m\n\u001b[0;32m     18\u001b[0m content_div \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmw-content-text\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m image_tags \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_div\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get the 'src' attribute of each 'img' tag and convert relative URLs to absolute URLs\u001b[39;00m\n\u001b[0;32m     22\u001b[0m image_urls \u001b[38;5;241m=\u001b[39m [urljoin(url, img[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m image_tags]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "download_image('https://www.google.com/search?sca_esv=022465d531b21f4c&rlz=1C1ONGR_enVN1095VN1095&sxsrf=ACQVn09xjnmZhAgsURHtSjC57FYSDGId_g:1709626979051&q=cat&tbm=isch&source=lnms&sa=X&ved=2ahUKEwiD-KLm2NyEAxVEqVYBHVxUBh0Q0pQJegQIDRAB&biw=1707&bih=898&dpr=1.5','cat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
